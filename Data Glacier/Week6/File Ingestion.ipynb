{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d2f5ddd-239e-47f2-9656-3122619fc4a8",
   "metadata": {},
   "source": [
    "## Approach 1: Reading the file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c42e8c41-a793-4e1e-b65e-0e8e030d7bb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2019-Nov.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:914\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('2019-Nov.csv',low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756b5c6-1ec4-4297-9bda-260ff5406a43",
   "metadata": {},
   "source": [
    "#### The file above is too large to process in memory using pandas.Let's try reading it in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1731b4b5-47d4-4a19-9cd7-12ff7cdcd9b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-Nov.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,chunksize\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Process each chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:504\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-Nov.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,chunksize\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Process each chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000\n",
    "chunks = pd.read_csv('2019-Nov.csv',low_memory=False,chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "data = pd.concat(chunk for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c279512-21f8-429d-96cd-bd883d6dad31",
   "metadata": {},
   "source": [
    "#### Even when using pandas to read the file in chunks, it's too large and experiences memory limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d11ec2-ad70-46df-976e-37477dcaf0e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-Nov.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39mchunk_size, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Process each chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:504\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m chunks \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-Nov.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39mchunk_size, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Process each chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\practice-env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000\n",
    "chunks = pd.read_csv('2019-Nov.csv', chunksize=chunk_size, low_memory=False)\n",
    "\n",
    "# Process each chunk\n",
    "data = pd.concat(chunk for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5587b40-17c2-4c85-988d-b51129be97b1",
   "metadata": {},
   "source": [
    "### Approach 2: Reading the file using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61d959d-01fa-4f9c-949b-bda8c021869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1929862f-62cd-436f-9929-f679c7157fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip cache purge\n",
    "# !pip install dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b17face-7ed2-4054-901a-b297e43d2074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIVIAN\\anaconda3\\envs\\practice-env\\lib\\site-packages\\dask\\dataframe\\__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1003461</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>489.07</td>\n",
       "      <td>520088904</td>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5000088</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>janome</td>\n",
       "      <td>293.65</td>\n",
       "      <td>530496790</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17302664</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creed</td>\n",
       "      <td>28.31</td>\n",
       "      <td>561587266</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3601530</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>lg</td>\n",
       "      <td>712.87</td>\n",
       "      <td>518085591</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004775</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>183.27</td>\n",
       "      <td>558856683</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
       "1  2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
       "2  2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
       "3  2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
       "4  2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
       "\n",
       "               category_code   brand   price    user_id  \\\n",
       "0     electronics.smartphone  xiaomi  489.07  520088904   \n",
       "1  appliances.sewing_machine  janome  293.65  530496790   \n",
       "2                        NaN   creed   28.31  561587266   \n",
       "3  appliances.kitchen.washer      lg  712.87  518085591   \n",
       "4     electronics.smartphone  xiaomi  183.27  558856683   \n",
       "\n",
       "                           user_session  \n",
       "0  4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  \n",
       "1  8e5f4f83-366c-4f70-860e-ca7417414283  \n",
       "2  755422e7-9040-477b-9bd2-6a6e8fd97387  \n",
       "3  3bfb58cd-7892-48cc-8020-2f17e6de6e7f  \n",
       "4  313628f1-68b8-460d-84f6-cec7a8796ef2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Read the CSV file using Dask\n",
    "df = dd.read_csv('2019-Nov.csv')\n",
    "\n",
    "# Converting to pandas\n",
    "df_result = df.compute()\n",
    "\n",
    "df_result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ec9fa-7202-4dbf-9c7c-c796379d1483",
   "metadata": {},
   "source": [
    "#### Dask has not experienced memory limitations as the data is read.Let's test the computational time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c058b4-2e55-400c-ab30-e8f2b89d2211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 171.2266070842743 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1003461</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>489.07</td>\n",
       "      <td>520088904</td>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5000088</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>janome</td>\n",
       "      <td>293.65</td>\n",
       "      <td>530496790</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17302664</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creed</td>\n",
       "      <td>28.31</td>\n",
       "      <td>561587266</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3601530</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>lg</td>\n",
       "      <td>712.87</td>\n",
       "      <td>518085591</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004775</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>183.27</td>\n",
       "      <td>558856683</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
       "1  2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
       "2  2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
       "3  2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
       "4  2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
       "\n",
       "               category_code   brand   price    user_id  \\\n",
       "0     electronics.smartphone  xiaomi  489.07  520088904   \n",
       "1  appliances.sewing_machine  janome  293.65  530496790   \n",
       "2                        NaN   creed   28.31  561587266   \n",
       "3  appliances.kitchen.washer      lg  712.87  518085591   \n",
       "4     electronics.smartphone  xiaomi  183.27  558856683   \n",
       "\n",
       "                           user_session  \n",
       "0  4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  \n",
       "1  8e5f4f83-366c-4f70-860e-ca7417414283  \n",
       "2  755422e7-9040-477b-9bd2-6a6e8fd97387  \n",
       "3  3bfb58cd-7892-48cc-8020-2f17e6de6e7f  \n",
       "4  313628f1-68b8-460d-84f6-cec7a8796ef2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Read the CSV file using Dask\n",
    "df = dd.read_csv('2019-Nov.csv')\n",
    "\n",
    "# To actually compute and bring the result into memory (for example, to convert to Pandas)\n",
    "df_result = df.compute()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time Taken: {end_time - start_time} seconds\")\n",
    "\n",
    "# Displaying the first five rows\n",
    "df_result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37583fca-7613-4b68-b9b2-f54221d302be",
   "metadata": {},
   "source": [
    "The time taken to read the first rows of the data using dusk is 170 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d253a079-3547-4171-8837-aae9cb0a01a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_time', 'event_type', 'product_id', 'category_id',\n",
       "       'category_code', 'brand', 'price', 'user_id', 'user_session'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c6ccc-991f-4ef8-b6d2-14a7078994bf",
   "metadata": {},
   "source": [
    "#### Performing basic validation\n",
    "By:\n",
    "    Clean the column names of the Dask DataFrame by:\n",
    "    \n",
    "    1. Removing leading/trailing spaces.\n",
    "        \n",
    "    2. Replacing spaces with underscores.\n",
    "\n",
    "Since all my columns are properly named using underscores and do not have any special characters, I'll only do the above two    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861dd6f2-9364-4f74-8cba-5ba656f0933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Function to perform all that at once\n",
    "def clean_column_names(df):\n",
    "    \n",
    "    # Removing trailing spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Removing special characters with underscore\n",
    "    df.columns = df.columns.str.replace(r'\\W+', '_', regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3bbf7f8-0b69-4add-bbff-0b07e195c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1003461</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>489.07</td>\n",
       "      <td>520088904</td>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5000088</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>janome</td>\n",
       "      <td>293.65</td>\n",
       "      <td>530496790</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17302664</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creed</td>\n",
       "      <td>28.31</td>\n",
       "      <td>561587266</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3601530</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>lg</td>\n",
       "      <td>712.87</td>\n",
       "      <td>518085591</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004775</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>183.27</td>\n",
       "      <td>558856683</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482625</th>\n",
       "      <td>2019-11-16 10:00:44 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>4803005</td>\n",
       "      <td>2053013554658804075</td>\n",
       "      <td>electronics.audio.headphone</td>\n",
       "      <td>sven</td>\n",
       "      <td>12.59</td>\n",
       "      <td>527910293</td>\n",
       "      <td>a7dfd0f3-8dc9-4471-a5d8-0f0cc68c4e27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482626</th>\n",
       "      <td>2019-11-16 10:00:44 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1005122</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>apple</td>\n",
       "      <td>1022.75</td>\n",
       "      <td>523045940</td>\n",
       "      <td>7b0f7f6e-a4e8-49b5-91d3-b77aa1f00b0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482627</th>\n",
       "      <td>2019-11-16 10:00:44 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1005182</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>samsung</td>\n",
       "      <td>977.86</td>\n",
       "      <td>518666558</td>\n",
       "      <td>d6bf8408-9597-4a0f-99d3-ba94f7b5e669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482628</th>\n",
       "      <td>2019-11-16 10:00:44 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>30100095</td>\n",
       "      <td>2053013556110033341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stanley</td>\n",
       "      <td>52.24</td>\n",
       "      <td>516687212</td>\n",
       "      <td>4b0b6a9a-6ba5-45b1-8f99-16369b6a9fbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482629</th>\n",
       "      <td>2019-11-16 10:00:44 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>26600353</td>\n",
       "      <td>2053013563517174627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.72</td>\n",
       "      <td>571430596</td>\n",
       "      <td>0937d51f-54dd-44f2-bd2c-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35391025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     event_time event_type  product_id          category_id  \\\n",
       "0       2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
       "1       2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
       "2       2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
       "3       2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
       "4       2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
       "...                         ...        ...         ...                  ...   \n",
       "482625  2019-11-16 10:00:44 UTC       view     4803005  2053013554658804075   \n",
       "482626  2019-11-16 10:00:44 UTC       view     1005122  2053013555631882655   \n",
       "482627  2019-11-16 10:00:44 UTC       view     1005182  2053013555631882655   \n",
       "482628  2019-11-16 10:00:44 UTC       view    30100095  2053013556110033341   \n",
       "482629  2019-11-16 10:00:44 UTC       cart    26600353  2053013563517174627   \n",
       "\n",
       "                      category_code    brand    price    user_id  \\\n",
       "0            electronics.smartphone   xiaomi   489.07  520088904   \n",
       "1         appliances.sewing_machine   janome   293.65  530496790   \n",
       "2                               NaN    creed    28.31  561587266   \n",
       "3         appliances.kitchen.washer       lg   712.87  518085591   \n",
       "4            electronics.smartphone   xiaomi   183.27  558856683   \n",
       "...                             ...      ...      ...        ...   \n",
       "482625  electronics.audio.headphone     sven    12.59  527910293   \n",
       "482626       electronics.smartphone    apple  1022.75  523045940   \n",
       "482627       electronics.smartphone  samsung   977.86  518666558   \n",
       "482628                          NaN  stanley    52.24  516687212   \n",
       "482629                          NaN      NaN    87.72  571430596   \n",
       "\n",
       "                                user_session  \n",
       "0       4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  \n",
       "1       8e5f4f83-366c-4f70-860e-ca7417414283  \n",
       "2       755422e7-9040-477b-9bd2-6a6e8fd97387  \n",
       "3       3bfb58cd-7892-48cc-8020-2f17e6de6e7f  \n",
       "4       313628f1-68b8-460d-84f6-cec7a8796ef2  \n",
       "...                                      ...  \n",
       "482625  a7dfd0f3-8dc9-4471-a5d8-0f0cc68c4e27  \n",
       "482626  7b0f7f6e-a4e8-49b5-91d3-b77aa1f00b0b  \n",
       "482627  d6bf8408-9597-4a0f-99d3-ba94f7b5e669  \n",
       "482628  4b0b6a9a-6ba5-45b1-8f99-16369b6a9fbe  \n",
       "482629            0937d51f-54dd-44f2-bd2c-12  \n",
       "\n",
       "[35391025 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the function\n",
    "\n",
    "clean_column_names(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3264b-4bc4-4f1f-96d2-23d4dd7338aa",
   "metadata": {},
   "source": [
    "### Approach 3: Reading the file using Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7882adc2-18fa-4709-8015-f1365127bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install modin[dask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3791eb30-565f-4848-8015-2580ab3a7fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modin.pandas as mpd\n",
    "# import time\n",
    "\n",
    "# # Start the timer\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Read the CSV file using Modin\n",
    "# df = mpd.read_csv('2019-Nov.csv')\n",
    "\n",
    "# # End the timer\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Print the elapsed time\n",
    "# print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# # Display the first few rows of the resulting DataFrame\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070a8e2-0814-47fd-b434-ca8a830ea2c6",
   "metadata": {},
   "source": [
    "### Writing Yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cf8837-f1a1-4669-82be-c9b22a137f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_time', 'event_type', 'product_id', 'category_id',\n",
       "       'category_code', 'brand', 'price', 'user_id', 'user_session'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b53bb5-6b5f-4060-98d2-0b627b6048da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read the YAML file\n",
    "def read_config_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filepath} was not found.\")\n",
    "        return None\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(f\"Error reading YAML file: {exc}\")\n",
    "        return None\n",
    "\n",
    "# Function to validate column headers\n",
    "def column_header(df_result, table_config):\n",
    "    df_result.columns = df_result.columns.str.strip()\n",
    "    df_result.columns = df_result.columns.str.lower()  # Ensures case-insensitivity\n",
    "    \n",
    "    # Removing special characters with underscore\n",
    "    df_result.columns = df_result.columns.str.replace(r'\\W+', '_', regex=True)\n",
    "\n",
    "    # Extract expected columns from YAML\n",
    "    expected_columns = list(table_config['columns'])\n",
    "    expected_columns.sort()\n",
    "\n",
    "    # Sort actual columns for comparison\n",
    "    actual_columns = list(df_result.columns)\n",
    "    actual_columns.sort()\n",
    "\n",
    "    # Compare sorted columns\n",
    "    if actual_columns == expected_columns:\n",
    "        print(\"Column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Column name and column length validation failed\")\n",
    "        mismatched_columns = set(actual_columns) - set(expected_columns)\n",
    "        missing_in_yaml = set(expected_columns) - set(actual_columns)\n",
    "        print(\"The following columns are not in the YAML file:\", list(mismatched_columns))\n",
    "        print(\"The following YAML columns are not in the file uploaded:\", list(missing_in_yaml))\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8424ec0-5d34-4b5f-a52c-01328910db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "file_name: 2019-Nov\n",
    "dataset_name: 2019-Nov.csv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "columns:\n",
    "  - event_time\n",
    "  - event_type\n",
    "  - product_id\n",
    "  - category_id\n",
    "  - category_code\n",
    "  - brand\n",
    "  - price\n",
    "  - user_id\n",
    "  - user_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f7bee1f-e607-4f2b-96a7-8cc89218d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading config file\n",
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abdcc06-cb30-480c-bedd-0f58f635d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-Nov.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check if the file type is being read correctly by reading the dataset name\n",
    "\n",
    "config_data['dataset_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1d93a8-03e0-40d5-af56-f0c9826afa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'file_name': '2019-Nov',\n",
       " 'dataset_name': '2019-Nov.csv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'columns': ['event_time',\n",
       "  'event_type',\n",
       "  'product_id',\n",
       "  'category_id',\n",
       "  'category_code',\n",
       "  'brand',\n",
       "  'price',\n",
       "  'user_id',\n",
       "  'user_session']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting data of config file\n",
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1730baa7-ef28-41ad-bcbc-689dd5d56a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal reading process of the file is usuall like this but cause of memory limitations let's comment out this lines\n",
    "# import pandas as pd\n",
    "# df_sample = pd.read_csv('2019-Nov.csv')\n",
    "# df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6591a8-dc94-4727-802f-a3b09eeb2acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1003461</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>489.07</td>\n",
       "      <td>520088904</td>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5000088</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>janome</td>\n",
       "      <td>293.65</td>\n",
       "      <td>530496790</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>17302664</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creed</td>\n",
       "      <td>28.31</td>\n",
       "      <td>561587266</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3601530</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>lg</td>\n",
       "      <td>712.87</td>\n",
       "      <td>518085591</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1004775</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>183.27</td>\n",
       "      <td>558856683</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
       "1  2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
       "2  2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
       "3  2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
       "4  2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
       "\n",
       "               category_code   brand   price    user_id  \\\n",
       "0     electronics.smartphone  xiaomi  489.07  520088904   \n",
       "1  appliances.sewing_machine  janome  293.65  530496790   \n",
       "2                        NaN   creed   28.31  561587266   \n",
       "3  appliances.kitchen.washer      lg  712.87  518085591   \n",
       "4     electronics.smartphone  xiaomi  183.27  558856683   \n",
       "\n",
       "                           user_session  \n",
       "0  4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  \n",
       "1  8e5f4f83-366c-4f70-860e-ca7417414283  \n",
       "2  755422e7-9040-477b-9bd2-6a6e8fd97387  \n",
       "3  3bfb58cd-7892-48cc-8020-2f17e6de6e7f  \n",
       "4  313628f1-68b8-460d-84f6-cec7a8796ef2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "\n",
    "# Print source file\n",
    "df = dd.read_csv(source_file,delimiter=config_data['inbound_delimiter'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6893820-3198-4c3b-bec7-975d21d66fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the column headers\n",
    "util.column_header(df,config_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c47a1-d8d1-4b30-8220-4b66ccba2348",
   "metadata": {},
   "source": [
    "### File summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852a5b9b-0b5c-4e4c-8178-353df41c27f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35391025\n",
      "9\n",
      "4723834880\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "num_rows = len(df)\n",
    "num_cols = len(df.columns)\n",
    "file_path = '2019-Nov.csv'\n",
    "size = os.path.getsize(file_path)\n",
    "\n",
    "print(num_rows)\n",
    "print(num_columns)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b751b9-3c29-4835-a088-d6bd7506e400",
   "metadata": {},
   "source": [
    "#### The file has:\n",
    "* 35391025 rows\n",
    "* 9 columns\n",
    "* 4723834880 bytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (practice-env)",
   "language": "python",
   "name": "practice-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
